{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfae43c7-8ca7-4292-b1ca-4499fedcd1e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'huggingface_hub'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#import umap\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mhdbscan\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer, AutoModel\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mTopicModelingPipeline\u001b[39;00m:\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, df):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\twitter-analytics-env\\lib\\site-packages\\transformers\\__init__.py:26\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Check the dependencies satisfy the minimal versions required.\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dependency_versions_check\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     28\u001b[0m     OptionalDependencyNotAvailable,\n\u001b[0;32m     29\u001b[0m     _LazyModule,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     42\u001b[0m     logging,\n\u001b[0;32m     43\u001b[0m )\n\u001b[0;32m     46\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mget_logger(\u001b[38;5;18m__name__\u001b[39m)  \u001b[38;5;66;03m# pylint: disable=invalid-name\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\twitter-analytics-env\\lib\\site-packages\\transformers\\dependency_versions_check.py:17\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdependency_versions_table\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deps\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m require_version, require_version_core\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# define which module versions we always want to check at run time\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# (usually the ones defined in `install_requires` in setup.py)\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# order specific notes:\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# - tqdm must be checked before tokenizers\u001b[39;00m\n\u001b[0;32m     26\u001b[0m pkgs_to_check_at_runtime \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython tqdm regex requests packaging filelock numpy tokenizers\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39msplit()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\twitter-analytics-env\\lib\\site-packages\\transformers\\utils\\__init__.py:30\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstants\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD, IMAGENET_STANDARD_MEAN, IMAGENET_STANDARD_STD\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdoc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     23\u001b[0m     add_code_sample_docstrings,\n\u001b[0;32m     24\u001b[0m     add_end_docstrings,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     28\u001b[0m     replace_return_docstrings,\n\u001b[0;32m     29\u001b[0m )\n\u001b[1;32m---> 30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeneric\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     31\u001b[0m     ContextManagers,\n\u001b[0;32m     32\u001b[0m     ExplicitEnum,\n\u001b[0;32m     33\u001b[0m     ModelOutput,\n\u001b[0;32m     34\u001b[0m     PaddingStrategy,\n\u001b[0;32m     35\u001b[0m     TensorType,\n\u001b[0;32m     36\u001b[0m     cached_property,\n\u001b[0;32m     37\u001b[0m     can_return_loss,\n\u001b[0;32m     38\u001b[0m     expand_dims,\n\u001b[0;32m     39\u001b[0m     find_labels,\n\u001b[0;32m     40\u001b[0m     flatten_dict,\n\u001b[0;32m     41\u001b[0m     is_jax_tensor,\n\u001b[0;32m     42\u001b[0m     is_numpy_array,\n\u001b[0;32m     43\u001b[0m     is_tensor,\n\u001b[0;32m     44\u001b[0m     is_tf_tensor,\n\u001b[0;32m     45\u001b[0m     is_torch_device,\n\u001b[0;32m     46\u001b[0m     is_torch_dtype,\n\u001b[0;32m     47\u001b[0m     is_torch_tensor,\n\u001b[0;32m     48\u001b[0m     reshape,\n\u001b[0;32m     49\u001b[0m     squeeze,\n\u001b[0;32m     50\u001b[0m     tensor_size,\n\u001b[0;32m     51\u001b[0m     to_numpy,\n\u001b[0;32m     52\u001b[0m     to_py_obj,\n\u001b[0;32m     53\u001b[0m     transpose,\n\u001b[0;32m     54\u001b[0m     working_or_temp_dir,\n\u001b[0;32m     55\u001b[0m )\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhub\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     57\u001b[0m     CLOUDFRONT_DISTRIB_PREFIX,\n\u001b[0;32m     58\u001b[0m     DISABLE_TELEMETRY,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     84\u001b[0m     send_example_telemetry,\n\u001b[0;32m     85\u001b[0m )\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimport_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     87\u001b[0m     ENV_VARS_TRUE_AND_AUTO_VALUES,\n\u001b[0;32m     88\u001b[0m     ENV_VARS_TRUE_VALUES,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    166\u001b[0m     torch_version,\n\u001b[0;32m    167\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\twitter-analytics-env\\lib\\site-packages\\transformers\\utils\\generic.py:29\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, ContextManager, List, Tuple\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimport_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_flax_available, is_tf_available, is_torch_available, is_torch_fx_proxy\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_flax_available():\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mjnp\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\twitter-analytics-env\\lib\\site-packages\\transformers\\utils\\import_utils.py:32\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpackaging\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m version\n\u001b[1;32m---> 32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m logging\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m importlib_metadata\n\u001b[0;32m     36\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mget_logger(\u001b[38;5;18m__name__\u001b[39m)  \u001b[38;5;66;03m# pylint: disable=invalid-name\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\twitter-analytics-env\\lib\\site-packages\\transformers\\utils\\logging.py:35\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     24\u001b[0m     CRITICAL,  \u001b[38;5;66;03m# NOQA\u001b[39;00m\n\u001b[0;32m     25\u001b[0m     DEBUG,  \u001b[38;5;66;03m# NOQA\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     31\u001b[0m     WARNING,  \u001b[38;5;66;03m# NOQA\u001b[39;00m\n\u001b[0;32m     32\u001b[0m )\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Optional\n\u001b[1;32m---> 35\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mhuggingface_hub\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mhf_hub_utils\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m auto \u001b[38;5;28;01mas\u001b[39;00m tqdm_lib\n\u001b[0;32m     39\u001b[0m _lock \u001b[38;5;241m=\u001b[39m threading\u001b[38;5;241m.\u001b[39mLock()\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'huggingface_hub'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import umap\n",
    "import hdbscan\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "\n",
    "class TopicModelingPipeline:\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "        self.model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "    def generate_umap_embeddings(self, n_components=5, n_neighbors=15, metric='cosine', min_dist=0.1):\n",
    "        # Generate BERT embeddings for the cleaned text column\n",
    "        embeddings = []\n",
    "        for text in self.df['cleaned_text']:\n",
    "            inputs = self.tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "            outputs = self.model(**inputs)[1].detach().numpy()\n",
    "            embeddings.append(outputs)\n",
    "\n",
    "        # Perform dimensionality reduction with UMAP\n",
    "        umap_embeddings = umap.UMAP(\n",
    "            n_components=n_components,\n",
    "            n_neighbors=n_neighbors,\n",
    "            metric=metric,\n",
    "            min_dist=min_dist\n",
    "        ).fit_transform(embeddings)\n",
    "\n",
    "        # Visualize the UMAP embeddings\n",
    "        fig = px.scatter(x=umap_embeddings[:,0], y=umap_embeddings[:,1])\n",
    "        fig.show()\n",
    "\n",
    "        return umap_embeddings\n",
    "\n",
    "    def generate_hdbscan_clusters(self, umap_embeddings, min_cluster_size=10, min_samples=1, cluster_selection_epsilon=0.5):\n",
    "        # Generate topic clusters with HDBSCAN\n",
    "        clusterer = hdbscan.HDBSCAN(\n",
    "            min_cluster_size=min_cluster_size,\n",
    "            min_samples=min_samples,\n",
    "            cluster_selection_epsilon=cluster_selection_epsilon\n",
    "        ).fit(umap_embeddings)\n",
    "\n",
    "        return clusterer.labels_\n",
    "\n",
    "    def visualize_clusters(self, umap_embeddings, cluster_labels):\n",
    "        # Visualize the HDBSCAN clusters against the UMAP embeddings\n",
    "        fig = px.scatter(\n",
    "            x=umap_embeddings[:,0],\n",
    "            y=umap_embeddings[:,1],\n",
    "            color=cluster_labels,\n",
    "            hover_data=[self.df['cleaned_text']]\n",
    "        )\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23a2aa0-289f-420c-a1b3-51111dc78d46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
